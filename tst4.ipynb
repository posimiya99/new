{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.optimizers import Adagrad\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Activation, Flatten, Dense\n",
    "\n",
    "# 学習用のデータを作る.\n",
    "image_list = []\n",
    "label_list = []\n",
    "\n",
    "# ./data/train 以下のorange,appleディレクトリ以下の画像を読み込む。\n",
    "for dir in os.listdir(\"data/train\"):\n",
    "    if dir == \".DS_Store\":\n",
    "        continue\n",
    "\n",
    "    dir1 = \"data/train/\" + dir \n",
    "    label = 0\n",
    "\n",
    "    if dir == \"A\":    # doraはラベル0\n",
    "        label = 0\n",
    "    elif dir == \"B\": # pikaはラベル1\n",
    "        label = 1\n",
    "\n",
    "    elif dir == \"C\": # shinはラベル2\n",
    "        label = 2\n",
    "\n",
    "\n",
    "    elif dir == \"D\": # pikaはラベル1\n",
    "        label = 3\n",
    "\n",
    "    elif dir == \"E\": # shinはラベル2\n",
    "        label = 4\n",
    "        \n",
    "    elif dir == \"F\": # shinはラベル2\n",
    "        label = 5\n",
    "\n",
    "\n",
    "    elif dir == \"G\": # pikaはラベル1\n",
    "        label = 6\n",
    "\n",
    "    elif dir == \"H\": # shinはラベル2\n",
    "        label = 7\n",
    "        \n",
    "    elif dir == \"I\": # pikaはラベル1\n",
    "        label = 8\n",
    "\n",
    "    elif dir == \"J\": # shinはラベル2\n",
    "        label = 9\n",
    "\n",
    "\n",
    "    elif dir == \"K\": # pikaはラベル1\n",
    "        label = 10\n",
    "\n",
    "\n",
    "    elif dir == \"L\": # shinはラベル2\n",
    "        label = 11\n",
    "        \n",
    "    elif dir == \"M\": # shinはラベル2\n",
    "        label = 12\n",
    "\n",
    "\n",
    "    elif dir == \"N\": # pikaはラベル1\n",
    "        label = 13\n",
    "\n",
    "    elif dir == \"O\": # shinはラベル2\n",
    "        label = 14        \n",
    "    \n",
    "    elif dir == \"P\": # pikaはラベル1\n",
    "        label = 15\n",
    "\n",
    "    elif dir == \"Q\": # shinはラベル2\n",
    "        label = 16\n",
    "\n",
    "\n",
    "    elif dir == \"R\": # pikaはラベル1\n",
    "        label = 17\n",
    "\n",
    "    elif dir == \"S\": # shinはラベル2\n",
    "        label = 18\n",
    "        \n",
    "    elif dir == \"T\": # shinはラベル2\n",
    "        label = 19\n",
    "\n",
    "\n",
    "    elif dir == \"U\": # pikaはラベル1\n",
    "        label = 20\n",
    "\n",
    "    elif dir == \"V\": # shinはラベル2\n",
    "        label = 21       \n",
    "        \n",
    "    elif dir == \"W\": # shinはラベル2\n",
    "        label = 22\n",
    "        \n",
    "    elif dir == \"X\": # shinはラベル2\n",
    "        label = 23\n",
    "\n",
    "\n",
    "    elif dir == \"Y\": # pikaはラベル1\n",
    "        label = 24\n",
    "\n",
    "    elif dir == \"Z\": # shinはラベル2\n",
    "        label = 25       \n",
    "        \n",
    "                \n",
    "        \n",
    "                \n",
    "        \n",
    "        \n",
    "    for file in os.listdir(dir1):\n",
    "        if file != \".DS_Store\":\n",
    "            # 配列label_listに正解ラベルを追加(どら:0 ぴか:1しん2)\n",
    "            label_list.append(label)\n",
    "            filepath = dir1 + \"/\" + file\n",
    "            # 画像を28x28pixelに変換し、1要素が[R,G,B]3要素を含む配列の28x28の２次元配列として読み込む。\n",
    "            # [R,G,B]はそれぞれが0-255の配列。\n",
    "            image = np.array(Image.open(filepath).resize((28, 28)))\n",
    "            image.shape\n",
    "        \n",
    "        \n",
    "            # 出来上がった配列をimage_listに追加。\n",
    "            image_list.append(image / 255.)\n",
    "\n",
    "# kerasに渡すためにnumpy配列に変換。\n",
    "image_list = np.array(image_list)\n",
    "\n",
    "# ラベルの配列を1と0からなるラベル配列に変更\n",
    "# 0 -> [1,0], 1 -> [0,1] という感じ。\n",
    "Y = to_categorical(label_list)\n",
    "\n",
    "# モデルを生成してニューラルネットを構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "model = model_from_json(open('lenet_AE.json').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 20)        1520      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 20)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 50)        25050     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2450)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               1225500   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 26)                13026     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 26)                0         \n",
      "=================================================================\n",
      "Total params: 1,265,096\n",
      "Trainable params: 1,265,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# オプティマイザにAdamを使用\n",
    "opt = Adam(lr=0.001)\n",
    "# モデルをコンパイル\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "model.load_weights('lenet_AE_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = np.array([\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\",])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('data/test/A/A0.png')  # 画像を読み込む。\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # BGR -> RGB\n",
    "\n",
    "def predict_single_img(img):\n",
    "    x = np.expand_dims(img, axis=0)  # バッチの次元を追加する\n",
    "    print(x.shape)\n",
    "    \n",
    "predict_single_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 100.00%\n",
      "Y: 0.00%\n",
      "B: 0.00%\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAEnlJREFUeJzt3XuMnOV1x/Fnbjuzs7uzN9br9Rq8GLCNr4DjSzAYDDiOS0K5tFG4FFK1ldoqDapUqUWKpaIoaiTSVqUVNI1KCSBVNEm5SBRIwICBQGOMwWZtA4bF+IZ37fVeZ3eub/9p//P5vZIbTVPO9/Onf3p2Zueds6/k857nSURRFAB8/iX/r98AgMag2AEnKHbACYodcIJiB5xIN/LFftL9nvyv/1rcn55UkxkN10/IpfvnvSTzzg2fyLx/z3X22n1r5drQOiXjpuaazGcyBZmfjnrNrHl6TK5tntHvbbZ1QuZN4/q9V6Ij9mtn1sm1oT6p47r9fQghhGzzKTNbveEv5NpaNSfzXa9/T+bVal7miYT63BJybZzbTiw94w/gzg44QbEDTlDsgBMUO+AExQ44QbEDTlDsgBMN7bO/taBd5gOnZmXeVSyZWU/9HLm2Z+wmmf/y1D0yf+vIg2a2ZfqLcu287z8p8+neQZknalWZN/3gt82s/upquTbkdZ88Xc7qPNkm87GJ+8yslN4p17a3/KnME0n9DMHMdJ+Z7X/nm3Jtpmla5rOzPTJvatLvLYpSMlcS0dn14bmzA05Q7IATFDvgBMUOOEGxA05Q7IATFDvgREP77CNdeua81Kx7j+0TnWbWN6H7orl6h8z7h+6Q+fCSfzaz6p+8Jde2rRiSeSjpy9CcL8q8dv27ZrbrzSvk2raYlm3XSb37cK1dz5Sn2m8zs9Mn75VrF7XMl3kpeYHMR6JVZlau2t+lEELoH3hR5qMn7J8dQgjVeqvME6mymdVj5tmjRF3mFu7sgBMUO+AExQ44QbEDTlDsgBMUO+BEQ1tvc6fGZX7JR3oEdiJntyvGc7oFdKpNb4ncmz1f5hurf2VmXQt+LtdGaT1Gmq/pMdFkpPOw0P7dOm8+LZceuFi3t674aFjmHzxhX5MQQsimLzezRfk1cu0F6X/Tr12/W+aRGAXN/ob+6p/z8j6ZL73w72X+9od/LvNU2X5vUU631uqJszuMlTs74ATFDjhBsQNOUOyAExQ74ATFDjhBsQNONLTPvq9rhcxrlRmZrzhqj7EmY857nsrr7ZjTg3oEtj1lb2N9Tu6oXFur6mcAykf08wWZ+bpX3tRlH7s8tUGPFX88uETm5VW655s7X49jdj9w0syWFPTvnU7obazz9U9lXm3dYmYd7+jtu8eW6c9ldOslMi/8xP69QwjhZMn+3EoHdVkWZvVx0Bbu7IATFDvgBMUOOEGxA05Q7IATFDvgBMUOONHQPnuuqmefB+fpfnSmZs+FL/7M7oOHEELHaf13LSrHbOf8tV1mlj5f98Groy0yH39+pcy77nhd5tluuxdeOam3sW5ObZB5cUz3utc+/4jMV9V3mFki5lZTrus5/p702zJPl+43s4k1i+Xa8W/cIPOxb+n9D1q/fkzm+UH7+5Z9vUuuzeU5shmAQLEDTlDsgBMUO+AExQ44QbEDTlDsgBMN7bOvGdLz6i8t0cfcdhTtPnu2queuKzF/16Kk3tu9Y/0BsVYuDVFZH0U9+Zru+Rau07PX5a5JM1u59H25ducTszKfmNLPCAwf1L9bb2XMzKqRvmalpozMc8VRmRfW288YnP6jS+XasF/vzZ7ptD/zEEKoHtXvvSNnl95EzHd1+5X2Mx8hhPC1cOZZfO7sgBMUO+AExQ44QbEDTlDsgBMUO+BEQ1tv88YrMl87VJR574S9vhrzm9RKuhXSskSPJJ7/mL1976k+3Z6aKeuRxdKH82Q+/Z8DMs8vPWxm3XP0+O3a3Bsyf3Zws8wfv/x3ZD67r9nMMkFvJX3d8Z0ybxt5V+aj5642syilx6nTffp48dbv6O3DUy26dTf5D3PMbPvVenT3+NV6e3ALd3bACYodcIJiB5yg2AEnKHbACYodcIJiB5xoaJ+9HrMD7qITejvoasoeiYyC7msmU/qY266rD8q87X57feVF3Uf/MKP7yeXqhMwndy+Xedetb9lhpEd3r7v5KZm3bV4m89rTuud7rKfPzF5I2UcqhxBCz6weQ+2565DMw1fskenpv9Rf/c679DMhST3ZGxJFfUT46OpTZlZZpceOFy3s0S9u4M4OOEGxA05Q7IATFDvgBMUOOEGxA05Q7IATDe2zx6mmdK88K47wrcVsJT01Z7/MW9fr7ZprPxRH9B7VffTZ9mtlnl2snwGYufxinU/aRzrnW9+Ta2stup+8sKBnxstvdsv8wtvt361/o95DYCY9LfPhtXofgJlt9nMbmUf0d23H/hdkvm7bmbdr/h8LBvplHubZn3vrpD4mu9SpPxcLd3bACYodcIJiB5yg2AEnKHbACYodcIJiB5xoaJ89CroXnqnrfvPBtufM7M3Uw3LttRtWyjy5Ss8fH/u2ffRx6dgGubZW0fPo2ZKey04/reebJ9OXmFnLTXvk2mhG76efL+njgSe2/a7MK1famxgM9Oj9C2rTej/+2XvKMs89YL92ao2+3qUuvd/+8B59XPSCtoUyr+ftXnniiL4HZ/cWZB6MxzK4swNOUOyAExQ74ATFDjhBsQNOUOyAExQ74MSv1Tx7IuiN5WvBngEuZofl2uVX2nuIhxDC5BHddx1eZ/eEq8/pfeNT//SZzCcK9h7iIYSwP6l73Zc9avd0ezZ2yLWJQlHmueQRmYf79DMCxfvPM7Py9XpP+9pr+rmM2kt6fVJcliitf/ZXL/s9mafn6H0Ahr+p93aP/the39Sm59Xzh3Myt3BnB5yg2AEnKHbACYodcIJiB5yg2AEnGtp6S8T8bSmnpmS+aOQWM1u4VI8U5pY9qvNks8ybR+zW3cGHeuXadMyxyWOtetTz4wt0e2vxC/aI69Sri+Xawk07ZZ6IuR20X6+3qj55r916S/1C/97JlH7xVLtu1VbFBGx1UI9TT76vvw+hTV/T3IgeHZ75F/s7M33vB3LtdJeuEwt3dsAJih1wgmIHnKDYAScodsAJih1wgmIHnPj1GnFN6L7pTNUe/evfpEcxm/P6V61MxPzdy9ojiQu+/2O5NErr8dn+akrmmyu65zt1yyN2GDPCGs3qfnAioY82zl2le8Kv/NlVZpYZ1UcTd47oXvYc/fhB6DhqZ6lefU0KPxiReUtBj8i+9Jr+Lr+cmDSzJSP6cxlbPy5zC3d2wAmKHXCCYgecoNgBJyh2wAmKHXCCYgecaGyfPaZnmyg3ybzpHLvP3nLVXrm2Nqt72Ymkfm/JNvvY5GSn7vGnIv03tTmpL8Nk0HPfbZH9uUV13e+t6FZ2qNb0e+so6KONU5sOmtn24mVybUtqRuaFEf273fg39jWN2Qk6hPP0z6536WcfRsePy/xQyf4up7P62YdFB/RR1mHRmf+ZOzvgBMUOOEGxA05Q7IATFDvgBMUOOEGxA040tM+ejDmSebqm+8lz1n1kZk39Y3JtVIqZZz+ujzY+fO9NZpau6+cD6mk9U/5q67/qfFw3w7uS9jMEC+vL5dqNt+q57eVbP5V5bVZf0y2VPWaW/OlKubb3lH72oeeQztvE+pl2fZ/rflZ/n1p7T8j824/tlvnx6y8yswML9BkIm57olHm44cz/zJ0dcIJiB5yg2AEnKHbACYodcIJiB5yg2AEnGtpnH+k+LPPd856X+e9v7DOzut7GOyRzeoB54jV9jnlp7wIzq3To87IfrD8l813RZzJvSeRkPpQ4aWY7Z9+Qa/ue3CTzS6/RffjJjH4GoH+ufc237D4m1xYP6XPvEzm99/v0XLtXPvT1l+XaI0f0Nc0f1XP8r6/UM+l9yVNm9tnofLm2ntbPNli4swNOUOyAExQ74ATFDjhBsQNOUOyAEw1tvU2GCZlfFlbIPL96p5lVYkZY6zF/18Zf0a23ljZ7XPLx7DNy7TvR2zLvCXq8thrp9lYyYY/YlrJ6O+Yn3tdbcG/a3y3zOd0HZF7uta9L4lZ7m+kQQijed67Mk8lWmc8k7c+t2KdHWGdjtuA+ndCfS7Kme8FZsYf31oftFnMIISzaPk/m4YfGe9KrAHxeUOyAExQ74ATFDjhBsQNOUOyAExQ74ERD++yH2gdlfvPKfplHBbtPn6zoI5mn340ZGzyo8+GsPY75i5ruo7cG3Q+uhJhzk2PUIrunm01l5dqPSvpo4Rde1eu3VfbLfOa4fc3SV+hrNtWrt8Fenn1I5uOt9tHGI2O6jz7ZrO+D2aoemY4bQ03N2COwF+0pyLXlJfrZCQt3dsAJih1wgmIHnKDYAScodsAJih1wgmIHnGhon/3URfoY29wme3vdEEKIZuwtlZPNs3Lt+CuLZJ4u6+2aDzcfMbPp+rRc2xyaZV4PMftg/y+IFnwIIYRsVvf4d+zS+anr9PMJHe/sMrOBn+2Qa3M9up/c1WwfBx1CCEur9jW74BU9E/6PN9wu86LY3yCEEJLlSZm3TNt9+E8X6yO+C1vKMjff01mtAvD/DsUOOEGxA05Q7IATFDvgBMUOOEGxA040tM+eufI9mXedZ88fhxBCScysz47quevZHStlnsnqhvR0ZPfx60H3XBPh7I7Y/VWI9FsLGf14QTg6VJL5vtzlMl+/wt7DIDWk++j9LS/LPFHTn+ux7DIz21O0j+AOIYSJn78i83wl5vt07lqZb18zamZ779ZHeN/ziT5nwMKdHXCCYgecoNgBJyh2wAmKHXCCYgecaGjr7eO/e1Tm31qi2x1rcvYxu8uGviDXPr36ezI/d0wf2XzhO182s+ak7l+VE3oksSnYRy6HEEI9Zk41imn9KYko5iuQ0uOWB398g8ynCqvNbHndOFv4v+Vq+ojv41PrZD5U22pmpa5n5dpDTz6pf/bWS2X+wRbd2pvssLeLHhjX17vnLLce584OOEGxA05Q7IATFDvgBMUOOEGxA05Q7IATDe2zHzuhR/PqR39L5p/m7LHAkXZ72+AQQlhQ0MdBr997o8xbg90XvSPcItc+Un1c5tPRlMwzGT2+m4zsUc+44drJSI+wXpDR22CfnKefEXg/2COwU3sulmuzFf18wrMbL5L5xtnHzGz9B3JpePSmB2U+tFn3uje9qO+je+fa49yrvjgk15bOcudx7uyAExQ74ATFDjhBsQNOUOyAExQ74ATFDjiRiOL2Gv4VWjF3j3yxqUTMlswpeyvpakzv8UtV3Q/OpisyHwxVM7u9pLfAHu07JvP/SL8q82OHdVN4pkn0o2Mub3fokvmd0W/KvL17ocz3L7Qf5Shn9b0mWdaPgYydp+fdb9xrz6xX3vuqXDvVore5zo7qa3pe04Uyf/ieT83s1KpxuTa1Y6/Mf/rdbWd8vII7O+AExQ44QbEDTlDsgBMUO+AExQ44QbEDTjR0nv3cdj07fSjm7ZRO2HmmoPvkz1V0I744o//uzW+1J8OzJb23etf882V+e1bPZecOHpX5uOizq1n3EELoCnqPgVQyI/Nwwj7KOoQQFpfs9fuW5+Xa5pK+pqWTrTL/9wXfMLPNB4/LtW1F/V0cn6uv6d1/8JHMB9dNm9klp/U5BF/J6d/bwp0dcIJiB5yg2AEnKHbACYodcIJiB5yg2AEnGtpnP/G3+szrzmX6TOuTf7jEzEo/65VrW748LPPehXbfM4QQ7nzI7qu2tNqz7iGEUD8wKfNEzObu2WbdV+2tn/3f7KqY0w8hhPqM7qPX0vq1xzvsPQi+8Eu9X36+qPdmn8np1z42355Jn2rTaztPyzg8s1V/n3ZfoWftk6P28we7cvr7kizqefdt1jq5CsDnBsUOOEGxA05Q7IATFDvgBMUOONHQ1luY0ybj2X7d/mr90dtmFl1zhVybEW2YEEJo++v39Gu/MNfMKif0SGJTpFtIiZgx1Goy7oxe/fPla9f1a08O6K9IOaaFNbDXHmuuZvVrF/MxW03HfCwLPlGjv/pnfzKgx2sfv1O33kJV/25RwW551qf1tud7VmzQr23gzg44QbEDTlDsgBMUO+AExQ44QbEDTlDsgBMN7bMXSrofPTkV15u0e5/zH9gj1w481Sfz15p0X3X3bYfN7Jrv2qO3IYRQ7NZ98GRMmzzmJOsQiRnZlDjNOYQQhlfrr8Ab39HjtfkR3ezefJc96hnT4o/to8cpN9kvkNaTvSEfs7X4tc90y3xU9NFDCGFOyf75Q9v18yiDg1mZh9vO/M/c2QEnKHbACYodcIJiB5yg2AEnKHbACYodcCIRRTFNXACfC9zZAScodsAJih1wgmIHnKDYAScodsAJih1wgmIHnKDYAScodsAJih1wgmIHnKDYAScodsAJih1wgmIHnKDYAScodsAJih1wgmIHnKDYAScodsAJih1w4r8AcwdmuwUl6LQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict_single_img(img):\n",
    "    x = np.expand_dims(img, axis=0)  # バッチの次元を追加する。\n",
    "\n",
    "    # 推論する。\n",
    "    scores = model.predict(x)[0]\n",
    "    top3_classes = scores.argsort()[-3:][::-1]\n",
    "\n",
    "    # 推論結果を表示する。\n",
    "    for name, score in zip(class_names[top3_classes], scores[top3_classes]):\n",
    "        print('{}: {:.2%}'.format(name, score))\n",
    "    print()\n",
    "\n",
    "img = cv2.imread('data/test/A/A0.png')  # 画像を読み込む。\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # BGR -> RGB\n",
    "img = cv2.resize(img, (28, 28), interpolation=cv2.INTER_CUBIC) # リサイズする。\n",
    "\n",
    "# 推論する。\n",
    "predict_single_img(img)\n",
    "\n",
    "# 画像を描画する。\n",
    "plt.axis('off')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.graph = tf.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.summary.writer.writer.FileWriter at 0x17dd351a400>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.summary.FileWriter('./bb', model.graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
